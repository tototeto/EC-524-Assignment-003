peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm) %>%
step_impute_knn(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
names(penguins)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm + bill_depth_mm + flipper_length_mm) %>%
step_impute_knn(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm + bill_depth_mm + body_mass_g) %>%
step_impute_knn(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_knn(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_knn(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_bag(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
rec_f %>% prep() %>% juice() %>% skim()
set.seed(35480384)
# Reload data
data('penguins')
# Define Model
mod_rf <- rand_forest(
mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine("ranger")
# Define Workflow
wkfl_rf <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_1)
# Parameter ranges
mtry_r = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_r = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_r = seq(from = 1, to = 10, by = 2)
# Parellel
tgrid_rf <- expand_grid(
mtry = mtry_r,
trees = trees_r,
min_n = min_n_r)
registerDoParallel(cl)
peng_cv_f <- rec_f %>% prep %>% juice %>% vfold_cv(v = nfold)
cv_rf <- wkfl_rf %>%
tune_grid(
peng_cv_f,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
# f for fancy
rec_f <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_bag(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome")
wkfl_f <- workflow() %>%
add_model(mod_rf) %>%
add_recipe(rec_f)
registerDoParallel(cl)
peng_cv_f <- rec_f %>% prep %>% juice %>% vfold_cv(v = nfold)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv_f,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
peng_cv_f <- rec_f %>% prep() %>% juice() %>% vfold_cv(v = nfold)
cv_f <- wkfl_f %>%
tune_grid(
peng_cv_f,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
show_best(cv_f)
best <- show_best(cv_f)
# Print results
print(paste(
"Tuned Parameters:\nNumber of Predictors Sampled:" + best$mtry[1]
))
print(paste(
"Tuned Parameters:\nNumber of Predictors Sampled:", best$mtry[1]
))
print(paste0(
"Tuned Parameters:\nNumber of Predictors Sampled:", best$mtry[1]
))
print(paste0(
"Tuned Parameters:\nNumber of Predictors Sampled:", best$mtry[1]
))
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:", best$mtry[1]
)
best <- show_best(cv_f)
best
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:",
best$mtry[1] , "\nNumber of Trees: ",
best$trees[1], "\nMinimum Data Points per Node: ", best$min_n[1]
)
best_rf <- show_best_rf(cv_rf)
best_rf <- show_best(cv_rf)
fit_rf <- wkfl_rf %>%
finalize_workflow(select_best(cv_rf, metric = 'accuracy')) %>%
fit(data = penguins)
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_rf$mtry[1] , "\nNumber of Trees: ",
best_rf$trees[1], "\nMinimum Data Points per Node: ", best_rf$min_n[1]
)
best
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:",
best$mtry[1] , "\nNumber of Trees: ",
best$trees[1], "\nMinimum Data Points per Node: ", best$min_n[1],
"\nAccuracy: ", best$mean[1]
)
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_rf$mtry[1] , "\nNumber of Trees: ",
best_rf$trees[1], "\nMinimum Data Points per Node: ", best_rf$min_n[1],
"\nAccuracy: ", best_rf$mean[1]
)
cat(
"Tuned Parameters:\nNumber of Predictors Sampled:",
best$mtry[1] , "\nNumber of Trees: ",
best$trees[1], "\nMinimum Data Points per Node: ", best$min_n[1],
"\nAccuracy: ", best$mean[1]
)
cat(
"------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best$mtry[1] , "\nNumber of Trees: ",
best$trees[1], "\nMinimum Data Points per Node: ", best$min_n[1],
"\nAccuracy: ", best$mean[1], "\n------------------------------------------------\n"
)
cat(
"\n------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_rf$mtry[1] , "\nNumber of Trees: ",
best_rf$trees[1], "\nMinimum Data Points per Node: ", best_rf$min_n[1],
"\nAccuracy: ", best_rf$mean[1],
"\n------------------------------------------------\n"
)
mtry_b = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_b = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_b = seq(from = 1, to = 10, by = 2)
learn_rate_b = floor(10^seq(from = -4, to = 0, by = 0.5))
tree_depth_b = seq(from=1,to=10,by=1)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_f)
mod_b <- boost_tree(
mode = "classification",
engine = "xgboost",
mtry = tune(),
trees = tune(),
min_n = tune(),
learn_rate = tune(),
tree_depth = tune(),
)
# Define parameter ranges
mtry_b = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_b = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_b = seq(from = 1, to = 10, by = 2)
learn_rate_b = floor(10^seq(from = -4, to = 0, by = 0.5))
tree_depth_b = seq(from=1,to=10,by=1)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_f)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_f)
registerDoParallel(cl)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_rf,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
install.packages(xgboost)
p_load(palmerpenguins, tidymodels, tidyverse, magrittr, skimr, DescTools, collapse, janitor, rpart, rpart.plot, doParallel, ranger, xgboost)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
stopCluster(cl)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "resampling") # Parellel
)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "resamples") # Parellel
)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
stopCluster(cl)
best_b <- show_best(cv_b)
show_notes(.Last.tune.result)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_b)
mod_b <- boost_tree(
mode = "classification",
engine = "xgboost",
mtry = tune(),
trees = tune(),
min_n = tune(),
learn_rate = tune(),
tree_depth = tune(),
)
rec_b <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_bag(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome") %>%
step_dummy(all_factor_predictors())
# Define parameter ranges
mtry_b = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_b = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_b = seq(from = 1, to = 10, by = 2)
learn_rate_b = floor(10^seq(from = -4, to = 0, by = 0.5))
tree_depth_b = seq(from=1,to=10,by=1)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_b)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
stopCluster(cl)
best_b <- show_best(cv_b)
# Print results
cat(
"\n------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_b$mtry[1] , "\nNumber of Trees: ",
best_b$trees[1], "\nMinimum Data Points per Node: ", best_b$min_n[1],
"\nAccuracy: ", best_b$mean[1],
"\n------------------------------------------------\n"
)
skim(best_b)
best_b
cat(
"\n------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_b$mtry[1] , "\nNumber of Trees: ",
best_b$trees[1], "\nMinimum Data Points per Node: ", best_b$min_n[1],
"\nAccuracy: ", best_b$mean[1],
"\nShrinkage Parameter: ", best_b$learn_rate,
"\nTree Depth: ", best_b$tree_depth,
"\n------------------------------------------------\n"
)
cat(
"\n------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_b$mtry[1] , "\nNumber of Trees: ",
best_b$trees[1], "\nMinimum Data Points per Node: ", best_b$min_n[1],
"\nAccuracy: ", best_b$mean[1],
"\nShrinkage Parameter: ", best_b$learn_rate[1],
"\nTree Depth: ", best_b$tree_depth[1],
"\n------------------------------------------------\n"
)
mod_b <- boost_tree(
mode = "classification",
engine = "xgboost",
mtry = tune(),
trees = tune(),
min_n = tune(),
learn_rate = tune(),
tree_depth = tune(),
)
rec_b <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_bag(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome") %>%
step_dummy(all_factor_predictors())
# Define parameter ranges
mtry_b = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_b = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_b = seq(from = 1, to = 10, by = 2)
learn_rate_b = (10^seq(from = -4, to = 0, by = 0.5))
tree_depth_b = seq(from=1,to=10,by=1)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_b)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
stopCluster(cl)
best_b <- show_best(cv_b)
# Print results
cat(
"\n------------------------------------------------\n",
"Tuned Parameters:\nNumber of Predictors Sampled:",
best_b$mtry[1] , "\nNumber of Trees: ",
best_b$trees[1], "\nMinimum Data Points per Node: ", best_b$min_n[1],
"\nAccuracy: ", best_b$mean[1],
"\nShrinkage Parameter: ", best_b$learn_rate[1],
"\nTree Depth: ", best_b$tree_depth[1],
"\n------------------------------------------------\n"
)
mod_b <- boost_tree(
mode = "classification",
engine = "xgboost",
mtry = tune(),
trees = tune(),
min_n = tune(),
learn_rate = tune(),
tree_depth = tune(),
)
rec_b <- recipe(penguins, species ~island + sex + bill_length_mm  + body_mass_g) %>%
step_impute_bag(all_numeric(), all_factor()) %>%
update_role(species, new_role = "outcome") %>%
step_dummy(all_factor_predictors())
# Define parameter ranges
mtry_b = seq(from = 1, to = ncol(penguins), length.out = ncol(penguins))
trees_b = floor(10^seq(from = 0, to = 3, by = 0.5))
min_n_b = seq(from = 1, to = 10, by = 2)
learn_rate_b = (10^seq(from = -4, to = 0, by = 0.5))
tree_depth_b = seq(from=1,to=10,by=1)
wkfl_b <-workflow() %>%
add_model(mod_b) %>%
add_recipe(rec_b)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
tgrid_b <- expand_grid(
mtry = mtry_b,
trees = trees_b,
min_n = min_n_b,
learn_rate = learn_rate_b,
tree_depth = tree_depth_b)
cv_b <- wkfl_b %>%
tune_grid(
peng_cv_f,
grid = tgrid_b,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE, verbose = TRUE, parallel_over = "everything") # Parellel
)
